## ğŸ“Œ æ³¨æ„äº‹é …

1. **ç’°å¢ƒéœ€æ±‚**  
   - éœ€å®‰è£ Python 3.8 ä»¥ä¸Š(å¯èƒ½)
   - éœ€å®‰è£ Pytorch åŠ Numpy  

2. **å¯èƒ½æœƒç™¼ç”Ÿå•é¡Œ**  
   - ç›®å‰åªæœ‰æ¸¬è©¦Pytorch `conv` ä»¥åŠ `FC` å…©å€‹å±¤çš„Weightæå–ã€è½‰æ›ã€‚å…¶ä»–ä¸¦æœªå¯¦è£ã€‚ 
   - å¦‚æœè®€å®Œç™¼ç¾é‚„æ˜¯ä¸æœƒç”¨ï¼Œè«‹æ´½ChatGptï¼ŒçœŸé¦™ã€‚  

  
## ğŸš€ å®‰è£èˆ‡ä½¿ç”¨
### 1ï¸âƒ£ åŸ·è¡Œ

```sh
py gen_params [model_file_name] [constant]
```

### 2ï¸âƒ£ ä¸€é»é»ä»‹ç´¹

é€™å€‹PythonåŸºæœ¬ä¸Šå°±æ˜¯èƒ½å°‡modelä¸­çš„åƒæ•¸æå–å‡ºä¾†ï¼Œä¸¦é€éç´”æ•´æ•¸è¨ˆç®—çš„æ–¹å¼ï¼Œç²å–æ‰€æœ‰éœ€è¦çš„åƒæ•¸ã€‚ç›®å‰æˆ‘å€‘åªæ”¯æŒåˆ°convä»¥åŠfcçš„åƒæ•¸æå–ï¼Œå¦‚æœæœ‰éœ€è¦å…¶ä»–çš„layerï¼Œå¯èƒ½å°±éœ€è¦å¤šåŠ ä¸€äº›ç¨‹å¼ç¢¼ä¸Šå»ã€‚

ç›®å‰ç¨‹å¼å¯è®€æ€§ä¸å¤ªé«˜ï¼Œå¯ä»¥æƒ³æˆå°±æ˜¯ç”¨ç¡¬å¹¹çš„æ–¹å¼å¯¦ç¾ã€‚å½ˆæ€§ä¸é«˜ï¼Œç”±æ–¼æˆ‘æ²’æ™‚é–“æå› æ­¤å°±å…ˆæš«æ™‚é€™æ¨£ã€‚

ä¸‹é¢çš„å…¬å¼è¦å¥½å¥½çœ‹ï¼Œä»¥åˆ©æ–¼ä½¿ç”¨åƒæ•¸é€²è¡Œæ¨å°ã€‚




### Quantize formula
```math
$Q_{out} = clmap(round(\dfrac{x_{input}}{scale}+zeropoint),Q_{min},Q_{max})$
```
ä¸€é–‹å§‹åœ¨æ¨¡å‹ä¸­çš„è¼¸å…¥å¿…é ˆå…ˆè½‰æ›ç‚ºint8æˆ–è€…uint8å½¢å¼ï¼Œå› æ­¤ä»¥ä¸Šå…¬å¼ç‚ºtensorflowç´”ç²¹å°‡tensorè½‰æ›ç‚ºquantçš„æ–¹å¼ã€‚

#### Conv quant formula
```math
$Q_{conv2D}=clamp(round(\dfrac{S_wS_{input}}{S_{conv2D}}\sum{(Q_{input}-zp_{input})*(Q_w-zp_w)}+zp_{conv2D}),Q_{min},Q_{max})$
```
æ¨¡å‹ä¸­conv2Dçš„å…¬å¼ç‚º
```math
$y_{f} = \sum{x_f}{w_f}+y_{bias}$
```
è€Œåœ¨ç¡¬é«”æ¶æ§‹ä¸­æˆ‘å€‘çš„è¼¸å…¥åŠæ¬Šé‡éƒ½æ˜¯åœ¨-128~127 or 0~255ç•¶ä¸­

å› æ­¤æˆ‘å€‘ä¾¿é ˆå°‡è¼¸å…¥éƒ½æ”¹æˆç‚ºQuantizeçš„ç‰ˆæœ¬

$S_3(y_q-y_{zp})= \sum{S_1}(x_q-x_{zp})S_2(w_q-w_{zp}) +y_{bias}$

$y_q-y_{zp} = \dfrac{S_1S_2}{S_3}\sum(x_q-x_{zp})(w_q-w_{zp})+\dfrac{y_{bias}}{S_3}$

æˆ‘å€‘å°‡ $M =\dfrac{S_1S_2}{S_3}$

å‰‡ï¼š

$(y_q-y_{zp})=M\sum{(x_q-x_{zp})(w_q-w_{zp})}+M\dfrac{y_{bias}}{S_1S_2}$

$(y_q-y_{zp}) = M\{\sum{(x_q-x_{zp})({w_q-w_{zp})+\dfrac{y_{bias}}{S_1S_2}}}\}$


$y_q = M\{\sum{(x_q-x_{zp})({w_q-w_{zp})+\dfrac{y_{bias}}{S_1S_2}}}\}+y_{zp}$

è€Œåˆ°é€™é‚Šæˆ‘å€‘å°±æ¨å°å‡ºä¾†æ­£ç¢ºçš„å…¬å¼ã€‚

è€Œåœ¨PytorchåŠTensorflowç•¶ä¸­éƒ½å¿…é ˆè¦å››æ¨äº”å…¥å¾Œåšå¤¾æ“ 

$output = clamp(round(y_q,Q_{min},Q_{max}))$

æˆ‘å€‘å¯ä»¥å®šç¾©multiplier $M\approx\dfrac{x_{scale}w_{scale}}{scale}$

è€Œ $M = 2^{-n}M_0$  

n : ç‚ºéé›¶æ•´æ•¸

$M_0:$ a fixed-point multiplier

$M :$ floating point 

ref:
[Quantization and Training of Neural Networks for Efficient
Integer-Arithmetic-Only Inference
](https://arxiv.org/pdf/1712.05877)
#### Conv forumla in Hardware
$y_q = M\{\sum{(x_q-x_{zp})({w_q-w_{zp})+\dfrac{y_{bias}}{S_1S_2}}}\}+y_{zp}$

$y_f=M(\sum{x_qw_q}-w_{zp}\sum{x_q}-x_{zp}\sum{w_q}+\sum{x_{zp}w_{zp}}+\dfrac{y_{bias}}{S_1S_2})+y_{zp}$

**ç”±æ–¼æˆ‘å€‘åœ¨Pytorchä¸­è¨“ç·´QATæ™‚ï¼Œåœ¨x86çš„é è¨­ä¸‹ï¼ŒWeightæœƒæ˜¯ä»¥Symmerticçš„æ–¹å¼å»è¨“ç·´ï¼Œå› æ­¤ä¸å­˜åœ¨zero pointsã€‚å…¬å¼æˆ‘å€‘å¯ä»¥ç›´æ¥æ”¹å¯«æˆ**


$a_2 = \sum{w_q}$ 

$y_f=Z_3+2^{-n}M_0(\sum{x_qw_q}+Z_1a_2+bias)$


